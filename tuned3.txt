Here is a summary of this model: 
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense (Dense)               (None, 3)                 12        
                                                                 
 dropout (Dropout)           (None, 3)                 0         
                                                                 
 dense_1 (Dense)             (None, 224)               896       
                                                                 
 dense_2 (Dense)             (None, 1)                 225       
                                                                 
=================================================================
Total params: 1,133
Trainable params: 1,133
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100

Epoch: 0, accuracy:0.2633,  loss:76.6530,  val_accuracy:0.4298,  val_loss:48.4207,  
.129/129 - 0s - loss: 76.6530 - accuracy: 0.2633 - val_loss: 48.4207 - val_accuracy: 0.4298 - 444ms/epoch - 3ms/step
Epoch 2/100
.129/129 - 0s - loss: 55.5302 - accuracy: 0.2689 - val_loss: 53.6066 - val_accuracy: 0.4465 - 115ms/epoch - 888us/step
Epoch 3/100
.129/129 - 0s - loss: 42.9064 - accuracy: 0.3195 - val_loss: 56.0248 - val_accuracy: 0.3893 - 104ms/epoch - 806us/step
Epoch 4/100
.129/129 - 0s - loss: 31.9744 - accuracy: 0.3839 - val_loss: 65.5360 - val_accuracy: 0.1628 - 107ms/epoch - 826us/step
Epoch 5/100
.129/129 - 0s - loss: 24.5695 - accuracy: 0.4350 - val_loss: 74.7657 - val_accuracy: 0.1541 - 105ms/epoch - 817us/step
Epoch 6/100
.129/129 - 0s - loss: 23.4217 - accuracy: 0.4406 - val_loss: 82.6576 - val_accuracy: 0.1216 - 105ms/epoch - 812us/step
Epoch 7/100
.129/129 - 0s - loss: 20.9905 - accuracy: 0.4496 - val_loss: 82.4097 - val_accuracy: 0.1331 - 106ms/epoch - 823us/step
Epoch 8/100
.129/129 - 0s - loss: 22.3682 - accuracy: 0.4661 - val_loss: 87.2150 - val_accuracy: 0.0977 - 105ms/epoch - 813us/step
Epoch 9/100
.129/129 - 0s - loss: 17.7062 - accuracy: 0.4860 - val_loss: 82.2201 - val_accuracy: 0.1259 - 105ms/epoch - 817us/step
Epoch 10/100
.129/129 - 0s - loss: 17.4974 - accuracy: 0.5069 - val_loss: 77.4849 - val_accuracy: 0.1548 - 108ms/epoch - 837us/step
Epoch 11/100
.129/129 - 0s - loss: 17.6661 - accuracy: 0.5147 - val_loss: 80.8037 - val_accuracy: 0.1946 - 104ms/epoch - 805us/step
Epoch 12/100
.129/129 - 0s - loss: 15.3085 - accuracy: 0.5249 - val_loss: 85.5126 - val_accuracy: 0.1100 - 105ms/epoch - 816us/step
Epoch 13/100
.129/129 - 0s - loss: 17.8043 - accuracy: 0.5038 - val_loss: 81.8755 - val_accuracy: 0.1295 - 109ms/epoch - 845us/step
Epoch 14/100
.129/129 - 0s - loss: 18.1196 - accuracy: 0.5237 - val_loss: 104.9316 - val_accuracy: 0.1722 - 105ms/epoch - 812us/step
Epoch 15/100
.129/129 - 0s - loss: 16.4216 - accuracy: 0.5081 - val_loss: 97.7221 - val_accuracy: 0.3546 - 105ms/epoch - 813us/step
Epoch 16/100
.129/129 - 0s - loss: 16.3737 - accuracy: 0.5218 - val_loss: 90.6220 - val_accuracy: 0.1874 - 104ms/epoch - 810us/step
Epoch 17/100
.129/129 - 0s - loss: 16.2580 - accuracy: 0.5239 - val_loss: 85.1871 - val_accuracy: 0.2467 - 105ms/epoch - 815us/step
Epoch 18/100
.129/129 - 0s - loss: 15.2333 - accuracy: 0.5519 - val_loss: 97.3123 - val_accuracy: 0.1317 - 108ms/epoch - 834us/step
Epoch 19/100
.129/129 - 0s - loss: 15.2413 - accuracy: 0.5140 - val_loss: 89.5114 - val_accuracy: 0.0883 - 108ms/epoch - 837us/step
Epoch 20/100
.129/129 - 0s - loss: 15.1622 - accuracy: 0.5266 - val_loss: 87.0561 - val_accuracy: 0.0781 - 107ms/epoch - 827us/step
Epoch 21/100
.129/129 - 0s - loss: 13.9130 - accuracy: 0.5339 - val_loss: 99.6377 - val_accuracy: 0.1093 - 105ms/epoch - 815us/step
Epoch 22/100
.129/129 - 0s - loss: 22.1499 - accuracy: 0.4938 - val_loss: 88.2847 - val_accuracy: 0.0890 - 105ms/epoch - 812us/step
Epoch 23/100
.129/129 - 0s - loss: 14.0702 - accuracy: 0.5500 - val_loss: 83.9008 - val_accuracy: 0.0810 - 106ms/epoch - 822us/step
Epoch 24/100
.129/129 - 0s - loss: 14.5076 - accuracy: 0.5509 - val_loss: 86.9420 - val_accuracy: 0.0803 - 104ms/epoch - 804us/step
Epoch 25/100
.129/129 - 0s - loss: 13.9818 - accuracy: 0.5303 - val_loss: 84.6103 - val_accuracy: 0.1223 - 106ms/epoch - 818us/step
Epoch 26/100
.129/129 - 0s - loss: 13.1010 - accuracy: 0.5344 - val_loss: 83.5118 - val_accuracy: 0.0890 - 104ms/epoch - 803us/step
Epoch 27/100
.129/129 - 0s - loss: 14.1479 - accuracy: 0.5305 - val_loss: 90.0219 - val_accuracy: 0.0991 - 106ms/epoch - 822us/step
Epoch 28/100
.129/129 - 0s - loss: 13.4860 - accuracy: 0.5271 - val_loss: 92.9903 - val_accuracy: 0.0760 - 106ms/epoch - 820us/step
Epoch 29/100
.129/129 - 0s - loss: 12.3729 - accuracy: 0.5602 - val_loss: 94.7249 - val_accuracy: 0.0774 - 105ms/epoch - 817us/step
Epoch 30/100
.129/129 - 0s - loss: 14.3539 - accuracy: 0.5332 - val_loss: 88.0095 - val_accuracy: 0.0789 - 104ms/epoch - 804us/step
Epoch 31/100
.129/129 - 0s - loss: 12.5966 - accuracy: 0.5458 - val_loss: 87.8796 - val_accuracy: 0.2048 - 103ms/epoch - 797us/step
Epoch 32/100
.129/129 - 0s - loss: 14.4276 - accuracy: 0.5378 - val_loss: 81.7535 - val_accuracy: 0.1020 - 103ms/epoch - 799us/step
Epoch 33/100
.129/129 - 0s - loss: 13.6780 - accuracy: 0.5580 - val_loss: 77.9235 - val_accuracy: 0.2713 - 103ms/epoch - 801us/step
Epoch 34/100
.129/129 - 0s - loss: 14.0577 - accuracy: 0.5201 - val_loss: 87.5929 - val_accuracy: 0.3784 - 106ms/epoch - 825us/step
Epoch 35/100
.129/129 - 0s - loss: 13.0620 - accuracy: 0.5269 - val_loss: 91.5322 - val_accuracy: 0.1208 - 104ms/epoch - 810us/step
Epoch 36/100
.129/129 - 0s - loss: 16.4268 - accuracy: 0.4977 - val_loss: 79.7605 - val_accuracy: 0.3097 - 104ms/epoch - 806us/step
Epoch 37/100
.129/129 - 0s - loss: 14.0037 - accuracy: 0.5407 - val_loss: 83.4294 - val_accuracy: 0.1512 - 105ms/epoch - 816us/step
Epoch 38/100
.129/129 - 0s - loss: 15.0984 - accuracy: 0.5159 - val_loss: 91.6711 - val_accuracy: 0.0738 - 105ms/epoch - 814us/step
Epoch 39/100
.129/129 - 0s - loss: 13.0906 - accuracy: 0.5487 - val_loss: 97.7302 - val_accuracy: 0.2757 - 105ms/epoch - 814us/step
Epoch 40/100
.129/129 - 0s - loss: 12.0091 - accuracy: 0.5704 - val_loss: 89.8794 - val_accuracy: 0.3965 - 105ms/epoch - 815us/step
Epoch 41/100
.129/129 - 0s - loss: 13.6952 - accuracy: 0.5356 - val_loss: 86.7850 - val_accuracy: 0.3973 - 104ms/epoch - 808us/step
Epoch 42/100
.129/129 - 0s - loss: 13.0650 - accuracy: 0.5259 - val_loss: 90.3388 - val_accuracy: 0.0687 - 105ms/epoch - 816us/step
Epoch 43/100
.129/129 - 0s - loss: 11.8510 - accuracy: 0.5614 - val_loss: 95.1188 - val_accuracy: 0.0716 - 104ms/epoch - 806us/step
Epoch 44/100
.129/129 - 0s - loss: 14.2549 - accuracy: 0.5028 - val_loss: 88.9542 - val_accuracy: 0.4443 - 106ms/epoch - 818us/step
Epoch 45/100
.129/129 - 0s - loss: 12.3423 - accuracy: 0.5359 - val_loss: 98.6219 - val_accuracy: 0.4334 - 105ms/epoch - 812us/step
Epoch 46/100
.129/129 - 0s - loss: 13.3996 - accuracy: 0.5159 - val_loss: 97.7459 - val_accuracy: 0.0680 - 105ms/epoch - 813us/step
Epoch 47/100
.129/129 - 0s - loss: 14.8317 - accuracy: 0.5293 - val_loss: 98.5053 - val_accuracy: 0.0615 - 105ms/epoch - 812us/step
Epoch 48/100
.129/129 - 0s - loss: 15.3202 - accuracy: 0.5385 - val_loss: 96.4974 - val_accuracy: 0.5072 - 109ms/epoch - 845us/step
Epoch 49/100
.129/129 - 0s - loss: 13.9789 - accuracy: 0.5130 - val_loss: 91.5917 - val_accuracy: 0.0593 - 105ms/epoch - 811us/step
Epoch 50/100
.129/129 - 0s - loss: 12.5624 - accuracy: 0.5269 - val_loss: 93.9830 - val_accuracy: 0.1433 - 104ms/epoch - 804us/step
Epoch 51/100
.129/129 - 0s - loss: 13.0767 - accuracy: 0.5585 - val_loss: 87.4528 - val_accuracy: 0.0673 - 104ms/epoch - 806us/step
Epoch 52/100
.129/129 - 0s - loss: 12.9381 - accuracy: 0.5354 - val_loss: 90.8174 - val_accuracy: 0.6889 - 106ms/epoch - 824us/step
Epoch 53/100
.129/129 - 0s - loss: 10.7922 - accuracy: 0.5553 - val_loss: 93.0961 - val_accuracy: 0.4826 - 104ms/epoch - 809us/step
Epoch 54/100
.129/129 - 0s - loss: 13.9297 - accuracy: 0.5227 - val_loss: 98.1455 - val_accuracy: 0.3271 - 106ms/epoch - 823us/step
Epoch 55/100
.129/129 - 0s - loss: 14.3548 - accuracy: 0.5084 - val_loss: 90.4923 - val_accuracy: 0.0709 - 104ms/epoch - 810us/step
Epoch 56/100
.129/129 - 0s - loss: 11.7833 - accuracy: 0.5308 - val_loss: 95.9474 - val_accuracy: 0.0644 - 107ms/epoch - 827us/step
Epoch 57/100
.129/129 - 0s - loss: 13.0435 - accuracy: 0.5222 - val_loss: 94.6002 - val_accuracy: 0.0550 - 106ms/epoch - 822us/step
Epoch 58/100
.129/129 - 0s - loss: 12.4057 - accuracy: 0.5363 - val_loss: 97.3377 - val_accuracy: 0.0608 - 104ms/epoch - 809us/step
Epoch 59/100
.129/129 - 0s - loss: 12.4030 - accuracy: 0.5072 - val_loss: 93.8692 - val_accuracy: 0.0586 - 105ms/epoch - 814us/step
Epoch 60/100
.129/129 - 0s - loss: 12.6569 - accuracy: 0.5400 - val_loss: 92.7861 - val_accuracy: 0.0593 - 106ms/epoch - 820us/step
Epoch 61/100
.129/129 - 0s - loss: 13.7451 - accuracy: 0.5067 - val_loss: 95.9417 - val_accuracy: 0.2438 - 112ms/epoch - 870us/step
Epoch 62/100
.129/129 - 0s - loss: 13.4866 - accuracy: 0.5312 - val_loss: 99.1416 - val_accuracy: 0.0832 - 106ms/epoch - 818us/step
Epoch 63/100
.129/129 - 0s - loss: 10.9561 - accuracy: 0.5332 - val_loss: 91.4127 - val_accuracy: 0.6505 - 103ms/epoch - 801us/step
Epoch 64/100
.129/129 - 0s - loss: 14.7642 - accuracy: 0.4734 - val_loss: 100.7904 - val_accuracy: 0.0579 - 104ms/epoch - 804us/step
Epoch 65/100
.129/129 - 0s - loss: 12.7934 - accuracy: 0.5064 - val_loss: 92.8636 - val_accuracy: 0.0912 - 105ms/epoch - 816us/step
Epoch 66/100
.129/129 - 0s - loss: 12.2473 - accuracy: 0.5539 - val_loss: 86.5960 - val_accuracy: 0.1397 - 105ms/epoch - 815us/step
Epoch 67/100
.129/129 - 0s - loss: 13.6347 - accuracy: 0.5339 - val_loss: 94.6849 - val_accuracy: 0.0586 - 106ms/epoch - 821us/step
Epoch 68/100
.129/129 - 0s - loss: 12.5107 - accuracy: 0.5449 - val_loss: 92.2870 - val_accuracy: 0.6686 - 106ms/epoch - 821us/step
Epoch 69/100
.129/129 - 0s - loss: 12.3295 - accuracy: 0.5458 - val_loss: 93.2951 - val_accuracy: 0.5543 - 105ms/epoch - 812us/step
Epoch 70/100
.129/129 - 0s - loss: 12.8763 - accuracy: 0.4962 - val_loss: 89.6288 - val_accuracy: 0.0557 - 105ms/epoch - 814us/step
Epoch 71/100
.129/129 - 0s - loss: 12.8812 - accuracy: 0.5400 - val_loss: 96.7184 - val_accuracy: 0.0550 - 106ms/epoch - 824us/step
Epoch 72/100
.129/129 - 0s - loss: 11.2462 - accuracy: 0.5147 - val_loss: 96.4392 - val_accuracy: 0.0709 - 106ms/epoch - 822us/step
Epoch 73/100
.129/129 - 0s - loss: 12.4703 - accuracy: 0.5568 - val_loss: 95.3038 - val_accuracy: 0.0658 - 107ms/epoch - 829us/step
Epoch 74/100
.129/129 - 0s - loss: 12.1710 - accuracy: 0.5478 - val_loss: 93.7380 - val_accuracy: 0.0919 - 104ms/epoch - 810us/step
Epoch 75/100
.129/129 - 0s - loss: 11.5537 - accuracy: 0.5473 - val_loss: 101.0101 - val_accuracy: 0.0564 - 107ms/epoch - 830us/step
Epoch 76/100
.129/129 - 0s - loss: 10.7472 - accuracy: 0.5115 - val_loss: 93.2668 - val_accuracy: 0.0521 - 105ms/epoch - 814us/step
Epoch 77/100
.129/129 - 0s - loss: 11.1472 - accuracy: 0.5529 - val_loss: 95.6574 - val_accuracy: 0.1143 - 105ms/epoch - 812us/step
Epoch 78/100
.129/129 - 0s - loss: 11.8645 - accuracy: 0.5512 - val_loss: 90.2444 - val_accuracy: 0.0579 - 105ms/epoch - 813us/step
Epoch 79/100
.129/129 - 0s - loss: 12.4436 - accuracy: 0.5456 - val_loss: 92.6561 - val_accuracy: 0.0543 - 104ms/epoch - 805us/step
Epoch 80/100
.129/129 - 0s - loss: 11.3452 - accuracy: 0.5142 - val_loss: 94.3581 - val_accuracy: 0.0492 - 104ms/epoch - 808us/step
Epoch 81/100
.129/129 - 0s - loss: 13.2658 - accuracy: 0.5057 - val_loss: 104.3603 - val_accuracy: 0.0528 - 107ms/epoch - 833us/step
Epoch 82/100
.129/129 - 0s - loss: 14.1606 - accuracy: 0.5072 - val_loss: 98.4652 - val_accuracy: 0.3104 - 105ms/epoch - 816us/step
Epoch 83/100
.129/129 - 0s - loss: 12.2345 - accuracy: 0.5526 - val_loss: 93.3291 - val_accuracy: 0.0521 - 106ms/epoch - 820us/step
Epoch 84/100
.129/129 - 0s - loss: 12.5407 - accuracy: 0.4743 - val_loss: 94.8838 - val_accuracy: 0.3698 - 105ms/epoch - 816us/step
Epoch 85/100
.129/129 - 0s - loss: 11.6511 - accuracy: 0.5227 - val_loss: 92.3593 - val_accuracy: 0.1975 - 106ms/epoch - 824us/step
Epoch 86/100
.129/129 - 0s - loss: 11.5595 - accuracy: 0.5254 - val_loss: 100.5217 - val_accuracy: 0.0644 - 105ms/epoch - 813us/step
Epoch 87/100
.129/129 - 0s - loss: 13.3097 - accuracy: 0.5524 - val_loss: 96.8488 - val_accuracy: 0.3343 - 105ms/epoch - 814us/step
Epoch 88/100
.129/129 - 0s - loss: 12.6355 - accuracy: 0.5089 - val_loss: 100.2378 - val_accuracy: 0.0868 - 104ms/epoch - 804us/step
Epoch 89/100
.129/129 - 0s - loss: 11.5017 - accuracy: 0.5218 - val_loss: 103.8898 - val_accuracy: 0.2677 - 105ms/epoch - 813us/step
Epoch 90/100
.129/129 - 0s - loss: 11.8493 - accuracy: 0.5123 - val_loss: 89.7356 - val_accuracy: 0.0514 - 105ms/epoch - 812us/step
Epoch 91/100
.129/129 - 0s - loss: 12.6816 - accuracy: 0.5098 - val_loss: 95.6905 - val_accuracy: 0.2945 - 104ms/epoch - 804us/step
Epoch 92/100
.129/129 - 0s - loss: 13.4560 - accuracy: 0.4996 - val_loss: 99.1304 - val_accuracy: 0.6823 - 104ms/epoch - 808us/step
Epoch 93/100
.129/129 - 0s - loss: 13.7980 - accuracy: 0.4600 - val_loss: 88.8499 - val_accuracy: 0.0514 - 104ms/epoch - 807us/step
Epoch 94/100
.129/129 - 0s - loss: 11.1847 - accuracy: 0.5381 - val_loss: 92.4714 - val_accuracy: 0.6389 - 105ms/epoch - 817us/step
Epoch 95/100
.129/129 - 0s - loss: 10.5991 - accuracy: 0.5084 - val_loss: 90.6602 - val_accuracy: 0.2221 - 106ms/epoch - 825us/step
Epoch 96/100
.129/129 - 0s - loss: 12.7814 - accuracy: 0.5295 - val_loss: 97.3547 - val_accuracy: 0.0608 - 105ms/epoch - 817us/step
Epoch 97/100
.129/129 - 0s - loss: 11.2554 - accuracy: 0.5252 - val_loss: 91.9355 - val_accuracy: 0.5514 - 104ms/epoch - 806us/step
Epoch 98/100
.129/129 - 0s - loss: 12.1982 - accuracy: 0.5291 - val_loss: 100.3640 - val_accuracy: 0.0680 - 106ms/epoch - 822us/step
Epoch 99/100
.129/129 - 0s - loss: 12.6166 - accuracy: 0.4967 - val_loss: 99.4955 - val_accuracy: 0.1541 - 105ms/epoch - 817us/step
Epoch 100/100
.129/129 - 0s - loss: 12.8504 - accuracy: 0.5016 - val_loss: 88.2957 - val_accuracy: 0.0557 - 104ms/epoch - 804us/step
Training predicted values 1 layer: 
[[-0.6177435]]
The actual labels 1 layer: 
1204     0.0
5372     0.0
2788     0.0
1722     0.0
2491     0.0
5415     0.0
3247    22.0
2675     0.0
5710     0.0
3894     0.0
Name: angle, dtype: float64
